<ion-accordion-group [multiple]="true" [value]="['model-selection', 'openrouter']" class="api-accordion">

  <!-- Global Model Selection -->
  <ion-accordion value="model-selection">
    <ion-item slot="header" lines="full">
      <ion-icon name="list-outline" slot="start"></ion-icon>
      <ion-label>
        <h3>AI Model Selection</h3>
        <p>Select your preferred AI model for content generation</p>
      </ion-label>
    </ion-item>
    <div slot="content" class="accordion-content">
      <div class="model-selection-wrapper">
        <div class="model-selection-container">
          <div class="model-header">
            <ion-label>Global Model</ion-label>
            <ion-button
              size="small"
              fill="outline"
              (click)="loadCombinedModels()"
              [disabled]="(!settings.openRouter.enabled || !settings.openRouter.apiKey) && (!settings.googleGemini.enabled || !settings.googleGemini.apiKey) && (!settings.replicate.enabled || !settings.replicate.apiKey) && (!settings.ollama.enabled || !settings.ollama.baseUrl) && (!settings.claude.enabled || !settings.claude.apiKey) && (!settings.openAICompatible.enabled || !settings.openAICompatible.baseUrl) || loadingModels"
              title="Load Models">
              {{ loadingModels ? 'Loading...' : 'Load Models' }}
            </ion-button>
          </div>
          <ng-select [(ngModel)]="settings.selectedModel"
                     [items]="combinedModels"
                     bindLabel="label"
                     bindValue="id"
                     [searchable]="true"
                     [clearable]="true"
                     [disabled]="(!settings.openRouter.enabled || !settings.openRouter.apiKey) && (!settings.googleGemini.enabled || !settings.googleGemini.apiKey) && (!settings.replicate.enabled || !settings.replicate.apiKey) && (!settings.ollama.enabled || !settings.ollama.baseUrl) && (!settings.claude.enabled || !settings.claude.apiKey) && (!settings.openAICompatible.enabled || !settings.openAICompatible.baseUrl)"
                     placeholder="Select or search model..."
                     (ngModelChange)="onGlobalModelChange()"
                     [loading]="loadingModels"
                     [virtualScroll]="true"
                     class="ng-select-custom"
                     appendTo="body">
            <ng-template ng-option-tmp let-item="item">
              <div class="model-option">
                <div class="model-option-header">
                  <app-provider-icon
                    [provider]="item.provider"
                    [size]="18"
                    [showTooltip]="true"
                    class="provider-icon"
                    [class.openrouter]="item.provider === 'openrouter'"
                    [class.claude]="item.provider === 'claude'"
                    [class.replicate]="item.provider === 'replicate'"
                    [class.ollama]="item.provider === 'ollama'"
                    [class.openai-compatible]="item.provider === 'openaiCompatible'"
                    [class.gemini]="item.provider === 'gemini'">
                  </app-provider-icon>
                  <span class="model-label">{{ item.label }}</span>
                </div>
                <div class="model-option-details">
                  <span class="model-cost">Input: {{ item.costInputEur }} | Output: {{ item.costOutputEur }}</span>
                  <span class="model-context">Context: {{ formatContextLength(item.contextLength) }}</span>
                </div>
                <div class="model-description" *ngIf="item.description">{{ item.description }}</div>
              </div>
            </ng-template>
          </ng-select>
          <div class="model-info">
            <p *ngIf="modelLoadError" class="error-text">{{ modelLoadError }}</p>
            <p *ngIf="!modelLoadError && combinedModels.length > 0" class="info-text">
              {{ combinedModels.length }} models available. Prices in EUR per 1M tokens.
            </p>
            <p *ngIf="!modelLoadError && combinedModels.length === 0 && (settings.openRouter.enabled || settings.googleGemini.enabled || settings.replicate.enabled || settings.ollama.enabled || settings.claude.enabled || settings.openAICompatible.enabled)" class="info-text">
              Click 'Load Models' to display available models.
            </p>
          </div>
        </div>
      </div>
    </div>
  </ion-accordion>

  <!-- OpenRouter Settings -->
  <ion-accordion value="openrouter">
    <ion-item slot="header" lines="full">
      <app-provider-icon slot="start" [provider]="'openrouter'" [size]="20"></app-provider-icon>
      <ion-label>
        <h3>OpenRouter API</h3>
        <p>Unified gateway to 100+ AI models</p>
      </ion-label>
      <ion-badge slot="end" [color]="settings.openRouter.enabled ? 'success' : 'medium'">
        {{ settings.openRouter.enabled ? 'Enabled' : 'Disabled' }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable OpenRouter</ion-label>
        <ion-toggle
          [(ngModel)]="settings.openRouter.enabled"
          (ngModelChange)="onProviderToggle('openRouter')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.openRouter.enabled">
        <ion-input
          type="password"
          [(ngModel)]="settings.openRouter.apiKey"
          (ngModelChange)="onApiKeyChange('openRouter')"
          placeholder="sk-or-v1-..."
          [disabled]="!settings.openRouter.enabled"
          label="API Key"
          labelPlacement="stacked"
          helperText="Find your OpenRouter API key at openrouter.ai/keys">
        </ion-input>
      </ion-item>

      <div class="model-info" [class.disabled]="!settings.openRouter.enabled">
        <p class="info-text">Use the global model selection above.</p>
      </div>

      <div class="settings-row" [class.disabled]="!settings.openRouter.enabled">
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.openRouter.temperature"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="2"
            step="0.1"
            [disabled]="!settings.openRouter.enabled"
            label="Temperature"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.openRouter.topP"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.openRouter.enabled"
            label="Top P"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
      </div>
    </div>
  </ion-accordion>

  <!-- Google Gemini Settings -->
  <ion-accordion value="gemini">
    <ion-item slot="header" lines="full">
      <ion-icon name="logo-google" slot="start" class="provider-icon gemini"></ion-icon>
      <ion-label>
        <h3>Google Gemini</h3>
        <p>Google's advanced multimodal AI</p>
      </ion-label>
      <ion-badge slot="end" [color]="settings.googleGemini.enabled ? 'success' : 'medium'">
        {{ settings.googleGemini.enabled ? 'Enabled' : 'Disabled' }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable Google Gemini</ion-label>
        <ion-toggle
          [(ngModel)]="settings.googleGemini.enabled"
          (ngModelChange)="onProviderToggle('googleGemini')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.googleGemini.enabled">
        <ion-input
          type="password"
          [(ngModel)]="settings.googleGemini.apiKey"
          (ngModelChange)="onApiKeyChange('googleGemini')"
          placeholder="AIza..."
          [disabled]="!settings.googleGemini.enabled"
          label="API Key"
          labelPlacement="stacked"
          helperText="Find your Google AI API key at aistudio.google.com/app/apikey">
        </ion-input>
      </ion-item>

      <div class="model-info" [class.disabled]="!settings.googleGemini.enabled">
        <p class="info-text">Use the global model selection above.</p>
      </div>

      <div class="settings-row" [class.disabled]="!settings.googleGemini.enabled">
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.googleGemini.temperature"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="2"
            step="0.1"
            [disabled]="!settings.googleGemini.enabled"
            label="Temperature"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.googleGemini.topP"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.googleGemini.enabled"
            label="Top P"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
      </div>

      <!-- Content Filter Settings -->
      <div *ngIf="settings.googleGemini.enabled" class="content-filter-section">
        <h4 class="section-title">Content Filter Settings</h4>

        <ion-item>
          <ion-label>Harassment</ion-label>
          <ion-select
            [(ngModel)]="settings.googleGemini.contentFilter.harassment"
            (ngModelChange)="settingsChange.emit()"
            interface="popover"
            slot="end">
            <ion-select-option value="BLOCK_NONE">Don't Block</ion-select-option>
            <ion-select-option value="BLOCK_ONLY_HIGH">Only high risks</ion-select-option>
            <ion-select-option value="BLOCK_MEDIUM_AND_ABOVE">Medium and high risks</ion-select-option>
            <ion-select-option value="BLOCK_LOW_AND_ABOVE">Low and higher risks</ion-select-option>
          </ion-select>
        </ion-item>

        <ion-item>
          <ion-label>Hate Speech</ion-label>
          <ion-select
            [(ngModel)]="settings.googleGemini.contentFilter.hateSpeech"
            (ngModelChange)="settingsChange.emit()"
            interface="popover"
            slot="end">
            <ion-select-option value="BLOCK_NONE">Don't Block</ion-select-option>
            <ion-select-option value="BLOCK_ONLY_HIGH">Only high risks</ion-select-option>
            <ion-select-option value="BLOCK_MEDIUM_AND_ABOVE">Medium and high risks</ion-select-option>
            <ion-select-option value="BLOCK_LOW_AND_ABOVE">Low and higher risks</ion-select-option>
          </ion-select>
        </ion-item>

        <ion-item>
          <ion-label>Sexually Explicit</ion-label>
          <ion-select
            [(ngModel)]="settings.googleGemini.contentFilter.sexuallyExplicit"
            (ngModelChange)="settingsChange.emit()"
            interface="popover"
            slot="end">
            <ion-select-option value="BLOCK_NONE">Don't Block</ion-select-option>
            <ion-select-option value="BLOCK_ONLY_HIGH">Only high risks</ion-select-option>
            <ion-select-option value="BLOCK_MEDIUM_AND_ABOVE">Medium and high risks</ion-select-option>
            <ion-select-option value="BLOCK_LOW_AND_ABOVE">Low and higher risks</ion-select-option>
          </ion-select>
        </ion-item>

        <ion-item>
          <ion-label>Dangerous Content</ion-label>
          <ion-select
            [(ngModel)]="settings.googleGemini.contentFilter.dangerousContent"
            (ngModelChange)="settingsChange.emit()"
            interface="popover"
            slot="end">
            <ion-select-option value="BLOCK_NONE">Don't Block</ion-select-option>
            <ion-select-option value="BLOCK_ONLY_HIGH">Only high risks</ion-select-option>
            <ion-select-option value="BLOCK_MEDIUM_AND_ABOVE">Medium and high risks</ion-select-option>
            <ion-select-option value="BLOCK_LOW_AND_ABOVE">Low and higher risks</ion-select-option>
          </ion-select>
        </ion-item>

        <ion-item>
          <ion-label>Civic Integrity</ion-label>
          <ion-select
            [(ngModel)]="settings.googleGemini.contentFilter.civicIntegrity"
            (ngModelChange)="settingsChange.emit()"
            interface="popover"
            slot="end">
            <ion-select-option value="BLOCK_NONE">Don't Block</ion-select-option>
            <ion-select-option value="BLOCK_ONLY_HIGH">Only high risks</ion-select-option>
            <ion-select-option value="BLOCK_MEDIUM_AND_ABOVE">Medium and high risks</ion-select-option>
            <ion-select-option value="BLOCK_LOW_AND_ABOVE">Low and higher risks</ion-select-option>
          </ion-select>
        </ion-item>
      </div>

      <div class="model-info" *ngIf="settings.googleGemini.enabled">
        <p class="info-text">
          <strong>Content Filter:</strong> Configurable safety settings for different content categories.
        </p>
      </div>
    </div>
  </ion-accordion>

  <!-- Claude API Settings -->
  <ion-accordion value="claude">
    <ion-item slot="header" lines="full">
      <app-provider-icon slot="start" [provider]="'claude'" [size]="20"></app-provider-icon>
      <ion-label>
        <h3>Claude (Anthropic)</h3>
        <p>Advanced reasoning AI assistant</p>
      </ion-label>
      <ion-badge slot="end" [color]="claudeConnectionStatus === 'success' ? 'success' : (settings.claude.enabled ? 'warning' : 'medium')">
        {{ claudeConnectionStatus === 'success' ? 'Connected' : (settings.claude.enabled ? 'Not tested' : 'Disabled') }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable Claude</ion-label>
        <ion-toggle
          [(ngModel)]="settings.claude.enabled"
          (ngModelChange)="onProviderToggle('claude')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.claude.enabled">
        <ion-input
          type="password"
          [(ngModel)]="settings.claude.apiKey"
          (ngModelChange)="onApiKeyChange('claude')"
          placeholder="sk-ant-api03-..."
          [disabled]="!settings.claude.enabled"
          label="API Key"
          labelPlacement="stacked"
          helperText="Find your Claude API key at console.anthropic.com">
        </ion-input>
      </ion-item>

      <div class="connection-test" [class.disabled]="!settings.claude.enabled">
        <ion-button
          size="small"
          fill="outline"
          (click)="testClaudeConnection()"
          [disabled]="!settings.claude.enabled || !settings.claude.apiKey || testingClaudeConnection"
          title="Test Connection">
          <ion-icon name="checkmark-circle" slot="start" *ngIf="claudeConnectionStatus === 'success'"></ion-icon>
          <ion-icon name="warning" slot="start" *ngIf="claudeConnectionStatus === 'error'"></ion-icon>
          {{ testingClaudeConnection ? 'Testing...' : 'Test Connection' }}
        </ion-button>
        <span *ngIf="claudeConnectionStatus === 'success'" class="connection-status success">Connected</span>
        <span *ngIf="claudeConnectionStatus === 'error'" class="connection-status error">Connection Failed</span>
      </div>

      <div class="model-info" [class.disabled]="!settings.claude.enabled">
        <p class="info-text">Use the global model selection above.</p>
      </div>

      <div class="settings-row" [class.disabled]="!settings.claude.enabled">
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.claude.temperature"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.claude.enabled"
            label="Temperature"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.claude.topP"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.claude.enabled"
            label="Top P"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.claude.topK"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="200"
            step="1"
            [disabled]="!settings.claude.enabled"
            label="Top K"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
      </div>
    </div>
  </ion-accordion>

  <!-- Ollama Settings -->
  <ion-accordion value="ollama">
    <ion-item slot="header" lines="full">
      <app-provider-icon slot="start" [provider]="'ollama'" [size]="20"></app-provider-icon>
      <ion-label>
        <h3>Ollama (Local AI)</h3>
        <p>Run AI models locally on your machine</p>
      </ion-label>
      <ion-badge slot="end" [color]="ollamaConnectionStatus === 'success' ? 'success' : (settings.ollama.enabled ? 'warning' : 'medium')">
        {{ ollamaConnectionStatus === 'success' ? 'Connected' : (settings.ollama.enabled ? 'Not tested' : 'Disabled') }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable Ollama</ion-label>
        <ion-toggle
          [(ngModel)]="settings.ollama.enabled"
          (ngModelChange)="onProviderToggle('ollama')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.ollama.enabled">
        <ion-input
          type="url"
          [(ngModel)]="settings.ollama.baseUrl"
          (ngModelChange)="onOllamaUrlChange()"
          placeholder="http://localhost:11434"
          [disabled]="!settings.ollama.enabled"
          label="Base URL"
          labelPlacement="stacked"
          helperText="URL where your Ollama server is running">
        </ion-input>
      </ion-item>

      <div class="connection-test" [class.disabled]="!settings.ollama.enabled">
        <ion-button
          size="small"
          fill="outline"
          (click)="testOllamaConnection()"
          [disabled]="!settings.ollama.enabled || !settings.ollama.baseUrl || testingOllamaConnection"
          title="Test Connection">
          <ion-icon name="checkmark-circle" slot="start" *ngIf="ollamaConnectionStatus === 'success'"></ion-icon>
          <ion-icon name="warning" slot="start" *ngIf="ollamaConnectionStatus === 'error'"></ion-icon>
          {{ testingOllamaConnection ? 'Testing...' : 'Test Connection' }}
        </ion-button>
        <span *ngIf="ollamaConnectionStatus === 'success'" class="connection-status success">Connected</span>
        <span *ngIf="ollamaConnectionStatus === 'error'" class="connection-status error">Connection Failed</span>
      </div>

      <div class="model-info" [class.disabled]="!settings.ollama.enabled">
        <p class="info-text">Use the global model selection above to choose from your local models. <br>
          Install models with: <code>ollama pull llama3.2</code></p>
        <p class="info-text warning-text">
          <ion-icon name="shield-outline"></ion-icon>
          <strong>Chrome Local Network Access:</strong> Chrome may block requests to localhost.<br>
          <span class="warning-detail">
            When prompted, click "Allow" to enable local network access.
          </span>
        </p>
      </div>

      <div class="settings-row" [class.disabled]="!settings.ollama.enabled">
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.ollama.temperature"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="2"
            step="0.1"
            [disabled]="!settings.ollama.enabled"
            label="Temperature"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.ollama.topP"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.ollama.enabled"
            label="Top P"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.ollama.maxTokens"
            (ngModelChange)="settingsChange.emit()"
            min="100"
            max="10000"
            step="100"
            [disabled]="!settings.ollama.enabled"
            label="Max Tokens"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
      </div>
    </div>
  </ion-accordion>

  <!-- OpenAI-Compatible Settings -->
  <ion-accordion value="openai-compatible">
    <ion-item slot="header" lines="full">
      <ion-icon name="server-outline" slot="start" style="color: #4caf50;"></ion-icon>
      <ion-label>
        <h3>OpenAI Compatible</h3>
        <p>LM Studio, LocalAI, vLLM, and more</p>
      </ion-label>
      <ion-badge slot="end" [color]="openAICompatibleConnectionStatus === 'success' ? 'success' : (settings.openAICompatible.enabled ? 'warning' : 'medium')">
        {{ openAICompatibleConnectionStatus === 'success' ? 'Connected' : (settings.openAICompatible.enabled ? 'Not tested' : 'Disabled') }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable OpenAI-Compatible</ion-label>
        <ion-toggle
          [(ngModel)]="settings.openAICompatible.enabled"
          (ngModelChange)="onProviderToggle('openAICompatible')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.openAICompatible.enabled">
        <ion-input
          type="url"
          [(ngModel)]="settings.openAICompatible.baseUrl"
          (ngModelChange)="onOpenAICompatibleUrlChange()"
          placeholder="http://localhost:1234"
          [disabled]="!settings.openAICompatible.enabled"
          label="Base URL"
          labelPlacement="stacked"
          helperText="URL where your OpenAI-compatible server is running (LM Studio default: localhost:1234)">
        </ion-input>
      </ion-item>

      <div class="connection-test" [class.disabled]="!settings.openAICompatible.enabled">
        <ion-button
          size="small"
          fill="outline"
          (click)="testOpenAICompatibleConnection()"
          [disabled]="!settings.openAICompatible.enabled || !settings.openAICompatible.baseUrl || testingOpenAICompatibleConnection"
          title="Test Connection">
          <ion-icon name="checkmark-circle" slot="start" *ngIf="openAICompatibleConnectionStatus === 'success'"></ion-icon>
          <ion-icon name="warning" slot="start" *ngIf="openAICompatibleConnectionStatus === 'error'"></ion-icon>
          {{ testingOpenAICompatibleConnection ? 'Testing...' : 'Test Connection' }}
        </ion-button>
        <span *ngIf="openAICompatibleConnectionStatus === 'success'" class="connection-status success">Connected</span>
        <span *ngIf="openAICompatibleConnectionStatus === 'error'" class="connection-status error">Connection Failed</span>
      </div>

      <div class="model-info" [class.disabled]="!settings.openAICompatible.enabled">
        <p class="info-text">Use the global model selection above to choose from your local models. <br>
          Works with LM Studio, LocalAI, vLLM, text-generation-webui, and other OpenAI-compatible servers.</p>
        <p class="info-text warning-text">
          <ion-icon name="warning-outline"></ion-icon>
          <strong>CORS Required:</strong> Enable CORS in your local server settings.<br>
          <span class="warning-detail">
            <strong>LM Studio:</strong> Local Server &rarr; Enable "Cross-Origin-Resource-Sharing (CORS)"<br>
            <strong>Ollama:</strong> Set OLLAMA_ORIGINS environment variable<br>
            <strong>Other servers:</strong> Consult your server's CORS documentation
          </span>
        </p>
        <p class="info-text warning-text">
          <ion-icon name="shield-outline"></ion-icon>
          <strong>Chrome Local Network Access:</strong> Chrome may block requests to localhost.<br>
          <span class="warning-detail">
            When prompted, click "Allow" to enable local network access.<br>
            If blocked without prompt: Go to <strong>chrome://settings/content/localNetworkAccess</strong>
          </span>
        </p>
      </div>

      <div class="settings-row" [class.disabled]="!settings.openAICompatible.enabled">
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.openAICompatible.temperature"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="2"
            step="0.1"
            [disabled]="!settings.openAICompatible.enabled"
            label="Temperature"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.openAICompatible.topP"
            (ngModelChange)="settingsChange.emit()"
            min="0"
            max="1"
            step="0.1"
            [disabled]="!settings.openAICompatible.enabled"
            label="Top P"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
        <ion-item>
          <ion-input
            type="number"
            [(ngModel)]="settings.openAICompatible.maxTokens"
            (ngModelChange)="settingsChange.emit()"
            min="100"
            max="10000"
            step="100"
            [disabled]="!settings.openAICompatible.enabled"
            label="Max Tokens"
            labelPlacement="stacked">
          </ion-input>
        </ion-item>
      </div>
    </div>
  </ion-accordion>

  <!-- Replicate Settings -->
  <ion-accordion value="replicate">
    <ion-item slot="header" lines="full">
      <app-provider-icon slot="start" [provider]="'replicate'" [size]="20"></app-provider-icon>
      <ion-label>
        <h3>Replicate</h3>
        <p>Cloud ML platform for images</p>
      </ion-label>
      <ion-badge slot="end" [color]="settings.replicate.enabled ? 'success' : 'medium'">
        {{ settings.replicate.enabled ? 'Enabled' : 'Disabled' }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable Replicate</ion-label>
        <ion-toggle
          [(ngModel)]="settings.replicate.enabled"
          (ngModelChange)="onProviderToggle('replicate')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.replicate.enabled">
        <ion-input
          type="password"
          [(ngModel)]="settings.replicate.apiKey"
          (ngModelChange)="onApiKeyChange('replicate')"
          placeholder="r8_..."
          [disabled]="!settings.replicate.enabled"
          label="API Key"
          labelPlacement="stacked"
          helperText="Find your Replicate API key at replicate.com/account/api-tokens">
        </ion-input>
      </ion-item>

      <div class="model-selection-wrapper" [class.disabled]="!settings.replicate.enabled">
        <div class="model-selection-container">
          <div class="model-header">
            <ion-label>Model</ion-label>
            <ion-button
              size="small"
              fill="outline"
              (click)="loadReplicateModels()"
              [disabled]="!settings.replicate.enabled || !settings.replicate.apiKey || loadingModels"
              title="Load models from Replicate">
              {{ loadingModels ? 'Loading...' : 'Load Models' }}
            </ion-button>
          </div>
          <ng-select [(ngModel)]="settings.replicate.model"
                     [items]="replicateModels"
                     bindLabel="label"
                     bindValue="id"
                     [searchable]="true"
                     [clearable]="true"
                     [disabled]="!settings.replicate.enabled"
                     placeholder="Select or search model..."
                     (ngModelChange)="settingsChange.emit()"
                     [loading]="loadingModels"
                     [virtualScroll]="true"
                     class="ng-select-custom">
          </ng-select>
          <div class="model-info">
            <p *ngIf="modelLoadError" class="error-text">{{ modelLoadError }}</p>
            <p *ngIf="!modelLoadError && replicateModels.length > 0" class="info-text">
              {{ replicateModels.length }} models available. Estimated prices in EUR per 1M tokens.
            </p>
            <p *ngIf="!modelLoadError && replicateModels.length === 0 && settings.replicate.enabled" class="info-text">
              Click 'Load Models' to display available models.
            </p>
            <p *ngIf="!settings.replicate.enabled" class="info-text">
              Format: owner/model-name (e.g. meta/llama-2-70b-chat)
            </p>
          </div>
        </div>
      </div>

      <ion-item [class.disabled]="!settings.replicate.enabled">
        <ion-input
          type="text"
          [(ngModel)]="settings.replicate.version"
          (ngModelChange)="settingsChange.emit()"
          placeholder="Leave empty for latest version"
          [disabled]="!settings.replicate.enabled"
          label="Version (optional)"
          labelPlacement="stacked">
        </ion-input>
      </ion-item>
    </div>
  </ion-accordion>

  <!-- fal.ai Settings -->
  <ion-accordion value="falai">
    <ion-item slot="header" lines="full">
      <app-provider-icon slot="start" [provider]="'fal'" [size]="20"></app-provider-icon>
      <ion-label>
        <h3>Fal.ai</h3>
        <p>Fast image generation platform</p>
      </ion-label>
      <ion-badge slot="end" [color]="settings.falAi.enabled ? 'success' : 'medium'">
        {{ settings.falAi.enabled ? 'Enabled' : 'Disabled' }}
      </ion-badge>
    </ion-item>
    <div slot="content" class="accordion-content">
      <ion-item>
        <ion-label>Enable fal.ai</ion-label>
        <ion-toggle
          [(ngModel)]="settings.falAi.enabled"
          (ngModelChange)="onProviderToggle('falAi')"
          slot="end">
        </ion-toggle>
      </ion-item>

      <ion-item [class.disabled]="!settings.falAi.enabled">
        <ion-input
          type="password"
          [(ngModel)]="settings.falAi.apiKey"
          (ngModelChange)="onFalAiApiKeyChange()"
          placeholder="fal_..."
          [disabled]="!settings.falAi.enabled"
          label="API Key"
          labelPlacement="stacked"
          helperText="Find your fal.ai API key at fal.ai/dashboard/keys">
        </ion-input>
      </ion-item>

      <div class="model-info" [class.disabled]="!settings.falAi.enabled">
        <p class="info-text">
          <ion-icon name="image-outline"></ion-icon>
          <strong>Image Generation:</strong> fal.ai is used for high-quality image generation models like Flux.
        </p>
        <p class="info-text" style="margin-top: 8px;">
          Configure and use fal.ai models in the <strong>Image Generation</strong> feature.
        </p>
      </div>
    </div>
  </ion-accordion>

</ion-accordion-group>
